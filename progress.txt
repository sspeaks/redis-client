# Ralph Progress Log
Started: Thu Feb 12 17:50:58 PST 2026

## Codebase Patterns
- Benchmarks use autocannon (Node.js) as the load generator; results are JSON files in `benchmarks/results/`
- Cluster benchmarks use `benchmarks/scripts/run-cluster.sh` which starts 5-node Redis cluster, seeds DB, builds apps, and runs `run-benchmarks.sh`
- Autocannon provides p97.5 (not p95) — use p97.5 as the closest available percentile
- Haskell REST benchmark is in `benchmarks/haskell-rest/` with cabal file `haskell-rest-benchmark.cabal`
- Current Haskell RTS flags: `-N` only (via `-with-rtsopts=-N`)
- Best RTS flags for throughput: `-H1024M -A128m -n8m -qb -N` (match-main config, +17.8%)
- Best RTS flags for tail latency: `--nonmoving-gc -N` (20ms p99.9)
- Typecheck via `nix-shell --run "cabal build all"` since `cabal` is not on PATH outside nix-shell
- Branch for this work: `ralph/gc-http-json-optimization` (created from main)
- Use `benchmarks/scripts/run-gc-tuning.sh` to run GC tuning benchmarks (pass binary path as arg)
- Autocannon latency keys in JSON: `p50`, `p97_5`, `p99`, `p99_9` (underscores, not dots)

---

## 2026-02-13 - US-001
- Captured pre-optimization baseline for all 4 REST benchmark scenarios in cluster mode
- Created `benchmarks/results/gc-http-json/baseline.md` with throughput, latency (p50/p97.5/p99/p99.9), and status codes
- Verified all numbers match COMPARISON.md exactly (0% variance)
- Key baseline: GET single H=87,492 vs .NET=138,479 (1.58× gap), the primary target for optimization
- Files changed: `benchmarks/results/gc-http-json/baseline.md` (new)
- **Learnings for future iterations:**
  - Existing cluster results in `benchmarks/results/cluster/` are from the same run documented in COMPARISON.md
  - The 1.58× gap on GET single is the primary optimization target (purest HTTP→Redis→HTTP path)
  - POST and Mixed are SQLite-bottlenecked — don't expect significant Redis/GC improvements there
  - p99.9 tail latency gap is most severe for POST (3.7× worse), likely GC-related
---

## 2026-02-13 - US-002
- Tested 5 GHC RTS flag combinations on GET single (cluster mode, 30s each)
- Created `benchmarks/scripts/run-gc-tuning.sh` — reusable script for RTS flag benchmarking
- Created `benchmarks/results/gc-http-json/gc-tuning.md` with comparison tables
- Results:
  - default (-N only): 88,081 req/s — baseline
  - aggressive-nursery (-A64m -n4m -H512m -N): 101,845 req/s (+15.6%)
  - **match-main (-H1024M -A128m -n8m -qb -N): 103,787 req/s (+17.8%)** — best throughput
  - nonmoving-gc (--nonmoving-gc -N): 86,558 req/s (−1.7%) — best p99.9 (20ms)
  - large-nursery-no-idle (-A128m -I0 -N): 102,558 req/s (+16.4%)
- GC tuning closes .NET gap from 1.58× to 1.33× on GET single
- Files changed:
  - `benchmarks/scripts/run-gc-tuning.sh` (new)
  - `benchmarks/results/gc-http-json/gc-tuning.md` (new)
  - `benchmarks/results/gc-http-json/gc_*.json` (5 raw result files)
- **Learnings for future iterations:**
  - Large nursery (-A128m+) is the single biggest throughput lever — reduces minor GC frequency
  - `-qb` (disable parallel nursery GC) helps in high-throughput scenarios by reducing GC thread sync
  - `-H1024M` (suggested heap) reduces major GC frequency — important for sustained load
  - Nonmoving GC trades throughput for consistent tail latency — use only when p99.9 matters more than throughput
  - Large nursery configs worsen p99.9 (28ms vs 21ms default) because individual GC pauses are longer
  - The match-main config is the clear winner for throughput benchmarks
  - Autocannon JSON latency fields use underscores: `p97_5`, `p99_9`
---
